# -*- coding: utf-8 -*-
"""signature forgery detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eqFq3qQR-ZG8vIkMla_Sk-0QVdT4tZMV
"""

from google.colab import files
files.upload()


!mkdir -p ~/.kaggle
!cp "kaggle (2).json" ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json


!kaggle datasets download -d robinreni/signature-verification-dataset


!unzip -o signature-verification-dataset.zip

import os
import numpy as np
import pandas as pd

from PIL import Image
import matplotlib.pyplot as plt

from tensorflow import keras as keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import img_to_array
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

import kagglehub
robinreni_signature_verification_dataset_path = kagglehub.dataset_download('robinreni/signature-verification-dataset')

print('Data source import complete.')

backbone_model = 'MobileNetV2'
freeze_conv_layers = True
img_size = 224
batch_size = 64
learning_rate = 1e-2
num_epoches = 5
steps_per_epoch = 100

data_path ="./sign_data/train"

def img_norm(x):
  return (x - x.mean(axis=(0,1,2), keepdims=True)) / x.std(axis=(0,1,2), keepdims=True)

class DataLoader:
  def __init__(self, dataset, batch_size=32, img_size=224, dir='./'):
    self.dataset = dataset
    self.batch_size = batch_size
    self.dir = dir
    self.img_size = img_size

  def shuffle(self):
    return self.dataset.sample(frac=1)

  def datagen(self, repeat_flag=True):
    num_samples = len(self.dataset)
    while True:

        self.dataset = self.shuffle()
        for batch in range(1, num_samples, self.batch_size):
            image1_batch_samples = self.dir + "/" + self.dataset.iloc[:, 0][batch:batch + self.batch_size]
            image2_batch_samples = self.dir + "/" + self.dataset.iloc[:, 1][batch:batch + self.batch_size]
            label_batch_samples = self.dataset.iloc[:, 2][batch:batch + self.batch_size]
            Image1, Image2, Label = [], [], []
            for image1, image2, label in zip(image1_batch_samples, image2_batch_samples, label_batch_samples):

                image1_data = Image.open(image1)
                image2_data = Image.open(image2)

                image1_data = image1_data.resize((self.img_size, self.img_size))
                image2_data = image2_data.resize((self.img_size, self.img_size))

                image1_data = img_to_array(image1_data)
                image2_data = img_to_array(image2_data)


                image1_data = img_norm(image1_data)
                image2_data = img_norm(image2_data)

                Image1.append(image1_data)
                Image2.append(image2_data)
                Label.append(label)
            Image1 = np.asarray(Image1).astype(np.float32)
            Image2 = np.asarray(Image2).astype(np.float32)
            Label = np.asarray(Label).astype(np.float32)
            yield (Image1, Image2), Label


        if not repeat_flag:
          break

def datagen(self, repeat_flag=True):
    while True:
        indices = np.random.choice(len(self.image1_paths), self.batch_size)
        image1_batch_samples = [self.image1_paths[i] for i in indices]
        image2_batch_samples = [self.image2_paths[i] for i in indices]
        label_batch_samples = [self.labels[i] for i in indices]

        Image1, Image2, Label = [], [], []

        for image1, image2, label in zip(image1_batch_samples, image2_batch_samples, label_batch_samples):
            try:

                image1 = os.path.join(self.root_dir, image1.lstrip('/'))
                image2 = os.path.join(self.root_dir, image2.lstrip('/'))


                print("Loading:", image1, image2)

                image1_data = Image.open(image1).resize((self.width, self.height))
                image2_data = Image.open(image2).resize((self.width, self.height))

                image1_data = np.array(image1_data) / 255.0
                image2_data = np.array(image2_data) / 255.0



                Image1.append(image1_data)
                Image2.append(image2_data)
                Label.append(label)
            except FileNotFoundError:
                print(f"File not found: {image1} or {image2}")
                continue

        Image1 = np.array(Image1)
        Image2 = np.array(Image2)
        Label = np.array(Label)

        yield [Image1, Image2], Label

        if not repeat_flag:
            break

dataset_path = "/kaggle/input/signature-verification-dataset/"
print(os.listdir(dataset_path))

train_set_file = "/kaggle/input/signature-verification-dataset/sign_data/train_data.csv"
test_set_file = "/kaggle/input/signature-verification-dataset/sign_data/test_data.csv"

train_val_set = pd.read_csv(train_set_file)
train_set, val_set = train_test_split(train_val_set, test_size=0.2)
test_set = pd.read_csv(test_set_file)

train_gen= DataLoader(train_set, batch_size, img_size, "./sign_data/train")
test_gen = DataLoader(test_set, batch_size, img_size, "./sign_data/train")
val_gen= DataLoader(val_set, batch_size, img_size, "./sign_data/train")

import os

for root, dirs, files in os.walk('./sign_data'):
    for name in files:
        if '003_24.PNG' in name:
            print(os.path.join(root, name))

!rm -rf ./sign_data/sign_data

base_path = "./sign_data/train"

train_batch = next(train_gen.datagen())
print("Train batch images shape:", train_batch[0][0].shape, train_batch[0][1].shape)
print("Train batch labels shape:", train_batch[1].shape)

from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2


def custom_cnn():
  model = Sequential()
  model.add(Conv2D(4, (3,3), activation='relu', input_shape=input_shape))
  model.add(MaxPooling2D(2,2))
  model.add(Dropout(0.25))

  model.add(Conv2D(16, (3,3), activation='relu'))
  model.add(MaxPooling2D(5,5))
  model.add(Dropout(0.25))

  model.add(Flatten())
  model.add(Dense(256, activation='relu'))

  return model


def def_base_model(backbone='xception', freeze_conv_layers=True):
  print('backbone model: ' + backbone)
  if backbone == 'Xception':
    base_model = Xception(weights='imagenet', include_top=False)
  elif backbone == 'InceptionV3':
    base_model = InceptionV3(weights='imagenet', include_top=False)
  elif backbone == 'ResNet50':
    base_model = ResNet50(weights='imagenet', include_top=False)
  elif backbone == 'MobileNetV2':
    base_model = MobileNetV2(weights='imagenet', include_top=False)
  else:
    raise("unexpected backbone model. Backbone model can be choosen from: "
    "'Xception', 'InceptionV3', 'MobileNetV2', and 'ResNet50'")

  x = base_model.output
  x = GlobalAveragePooling2D()(x)
  x = Flatten()(x)
  x = Dense(128, activation='relu')(x)


  if freeze_conv_layers:
    print('freeze convolutional layers ...')
    for layer in base_model.layers:
        layer.trainable = False
  model = Model(inputs=base_model.input, outputs=x)
  return model

def abs_diff(tensors):
    x, y = tensors
    return K.abs(x - y)

def abs_diff_output_shape(input_shape):
    return input_shape[0]

def siamese_model(input_shape, backbone_model='custom_cnn', freeze_conv_layers=True):
    input1 = Input(input_shape)
    input2 = Input(input_shape)

    if backbone_model == 'custom_cnn':
        base_model = custom_cnn()
    else:
        base_model = def_base_model(backbone_model, freeze_conv_layers)

    embedding1 = base_model(input1)
    embedding2 = base_model(input2)

    loss_layer = Lambda(abs_diff, output_shape=abs_diff_output_shape)
    manhattan_distance = loss_layer([embedding1, embedding2])

    output = Dense(1, activation='sigmoid')(manhattan_distance)

    network = Model(inputs=[input1, input2], outputs=output)
    return network

model = siamese_model((img_size, img_size, 3), backbone_model, freeze_conv_layers)
model.summary()

def f1_score(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    recall = true_positives / (possible_positives + K.epsilon())
    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
    return f1_val

lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=learning_rate,
    decay_steps=5*steps_per_epoch,
    decay_rate=0.5)

optimizer = Adam(learning_rate=lr_schedule, weight_decay=0.2)
model.compile(loss="binary_crossentropy", optimizer=optimizer, metrics=['accuracy', f1_score])

early_stopper =  EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)
custom_callback = [early_stopper]

print("Training!")

checkpoint_filepath = data_path + '/best_model.keras'
model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

import tensorflow as tf


train_dataset = tf.data.Dataset.from_generator(
    train_gen.datagen,
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.float32)
    )
)


val_dataset = tf.data.Dataset.from_generator(
    val_gen.datagen,
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.float32)
    )
)

history = model.fit(
    train_dataset,
    verbose=1,
    steps_per_epoch=steps_per_epoch,
    epochs=num_epoches,
    validation_data=val_dataset,
    validation_steps=1,
    callbacks=[model_checkpoint_callback]
)

print(history.history.keys())

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['f1_score'])
plt.plot(history.history['val_f1_score'])
plt.title('model f1_score')
plt.ylabel('f1_score')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

model.save(backbone_model + '.h5', overwrite=True)

from tensorflow import keras
from tensorflow.keras import backend as K

def abs_diff(inputs):
    x, y = inputs
    return K.abs(x - y)

def abs_diff_output_shape(input_shapes):
    shape1, shape2 = input_shapes
    return shape1

def f1_score(y_true, y_pred):
    y_pred = K.round(y_pred)
    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)
    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)
    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)

    precision = tp / (tp + fp + K.epsilon())
    recall = tp / (tp + fn + K.epsilon())
    f1 = 2 * precision * recall / (precision + recall + K.epsilon())
    return K.mean(f1)

custom_objects = {
    "abs_diff": abs_diff,
    "abs_diff_output_shape": abs_diff_output_shape,
    "f1_score": f1_score
}

loaded_model = keras.models.load_model(checkpoint_filepath, custom_objects=custom_objects)

result = loaded_model.evaluate(
    test_gen.datagen(repeat_flag=False),
    verbose=1
)

print("Evaluation Result:", result)

from tensorflow.keras.preprocessing import image
img_path1 = '/content/sign_data/test/050/10_050.png'
img_path2 = '/content/sign_data/test/050_forg/04_0125050.PNG'

img1 = image.load_img(img_path1, target_size=(224, 224))
img2 = image.load_img(img_path2, target_size=(224, 224))

img_array1 = image.img_to_array(img1)
img_array2 = image.img_to_array(img2)

img_array1 = np.expand_dims(img_array1, axis=0)
img_array2 = np.expand_dims(img_array2, axis=0)

prediction = model.predict([img_array1, img_array2])
print("Prediction:", prediction)

if prediction[0] > 0.5:
    print("توقيع مزور")
else:
    print("توقيع أصلي")







